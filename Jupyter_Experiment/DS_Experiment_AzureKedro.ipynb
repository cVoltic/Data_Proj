{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.6.0 to work with Space-Flight-Predictor\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    #Start by loading a workspace from configuration file\n",
    "    #Import azure core package\n",
    "\"\"\"\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 3 files\n",
      "Uploading ./data/companies.csv\n",
      "Uploading ./data/reviews.csv\n",
      "Uploading ./data/shuttles.csv\n",
      "Uploaded ./data/companies.csv, 1 files out of an estimated total of 3\n",
      "Uploaded ./data/reviews.csv, 2 files out of an estimated total of 3\n",
      "Uploaded ./data/shuttles.csv, 3 files out of an estimated total of 3\n",
      "Uploaded 3 files\n",
      "Dataset ready.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    #Prepare data by first uploading it to the cloud blob storage\n",
    "\"\"\"\n",
    "\n",
    "from azureml.core import Dataset\n",
    "\n",
    "#Pre-transformation step: turn xlsx to .csv\n",
    "import pandas as pd\n",
    "pre_df = pd.read_excel(\"./data/shuttles.xlsx\")\n",
    "pre_df.to_csv(\"./data/shuttles.csv\", sep=\",\")\n",
    "\n",
    "#Begin uploading data to Azure Blob Storage\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload_files(files=['./data/companies.csv', './data/reviews.csv', './data/shuttles.csv'], # Upload the csv files in /data\n",
    "                       target_path='space-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "#Tabular dataset is structured data\n",
    "companies_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'space-data/companies.csv'))\n",
    "reviews_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'space-data/reviews.csv'))\n",
    "shuttles_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'space-data/shuttles.csv'))\n",
    "\n",
    "# Register the tabular dataset\n",
    "# Data Extraction Step (Essentially)\n",
    "companies_data_set = companies_data_set.register(workspace=ws, \n",
    "                           name='space companies dataset',\n",
    "                           description='companies data',\n",
    "                           tags = {'format':'CSV'},\n",
    "                           create_new_version=True)\n",
    "reviews_data_set = reviews_data_set.register(workspace=ws, \n",
    "                           name='space reviews dataset',\n",
    "                           description='companies data',\n",
    "                           tags = {'format':'CSV'},\n",
    "                           create_new_version=True)\n",
    "shuttles_data_set = shuttles_data_set.register(workspace=ws, \n",
    "                           name='space shuttles dataset',\n",
    "                           description='shuttles data',\n",
    "                           tags = {'format':'CSV'},\n",
    "                           create_new_version=True)\n",
    "\n",
    "print('Dataset ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space_pipeline_dir\n"
     ]
    }
   ],
   "source": [
    "#Create a Folder to Store Pipeline Works\n",
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'space_pipeline_dir'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Transformation Functions\n",
    "#To be use in ETL works\n",
    "import pandas as pd\n",
    "\n",
    "#Define function to transform our data.\n",
    "def _is_true(x):\n",
    "    return x == \"t\"\n",
    "\n",
    "#percent to decimal\n",
    "def _parse_percentage(x):\n",
    "    if (x == None):\n",
    "        return 0.0\n",
    "    if (x != \"\"):\n",
    "        return float(x.replace(\"%\", \"\"))/100.\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "\n",
    "#Remove dollar signs and comma from money unit\n",
    "def _parse_money(x):\n",
    "    return float(x.replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "\n",
    "#apply functions to data\n",
    "def preprocess_companies(companies: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Preprocess the data for companies.\n",
    "\n",
    "        Args:\n",
    "            companies: Source data.\n",
    "        Returns:\n",
    "            Preprocessed data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    companies[\"iata_approved\"] = companies[\"iata_approved\"].apply(_is_true)\n",
    "\n",
    "    companies[\"company_rating\"] = companies[\"company_rating\"].apply(_parse_percentage)\n",
    "\n",
    "    return companies\n",
    "\n",
    "\n",
    "#apply functions to data\n",
    "def preprocess_shuttles(shuttles: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Preprocess the data for shuttles.\n",
    "\n",
    "        Args:\n",
    "            shuttles: Source data.\n",
    "        Returns:\n",
    "            Preprocessed data.\n",
    "\n",
    "    \"\"\"\n",
    "    shuttles[\"d_check_complete\"] = shuttles[\"d_check_complete\"].apply(_is_true)\n",
    "\n",
    "    shuttles[\"moon_clearance_complete\"] = shuttles[\"moon_clearance_complete\"].apply(_is_true)\n",
    "\n",
    "    shuttles[\"price\"] = shuttles[\"price\"].apply(_parse_money)\n",
    "\n",
    "    return shuttles\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Preprocess step to cleanup data\n",
    "preprocessed_companies_data_set = preprocess_companies(companies_data_set.to_pandas_dataframe())\n",
    "preprocessed_shuttles_data_set = preprocess_shuttles(shuttles_data_set.to_pandas_dataframe())\n",
    "preprocessed_reviews_data_set = reviews_data_set.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More DataEngineer Step\n",
    "#Create Master Table\n",
    "def create_master_table(shuttles: pd.DataFrame, companies: pd.DataFrame, reviews: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Combines all data to create a master table.\n",
    "\n",
    "        Args:\n",
    "            shuttles: Preprocessed data for shuttles.\n",
    "            companies: Preprocessed data for companies.\n",
    "            reviews: Source data for reviews.\n",
    "        Returns:\n",
    "            Master table.\n",
    "\n",
    "    \"\"\"\n",
    "    rated_shuttles = shuttles.merge(reviews, left_on=\"id\", right_on=\"shuttle_id\")\n",
    "\n",
    "    with_companies = rated_shuttles.merge(\n",
    "        companies, left_on=\"company_id\", right_on=\"id\"\n",
    "    )\n",
    "\n",
    "    master_table = with_companies.drop([\"shuttle_id\", \"company_id\"], axis=1)\n",
    "    master_table = master_table.dropna()\n",
    "    return master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/space_master.csv\n",
      "Uploaded ./data/space_master.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "#Create Master Table and Store it in the blob storage\n",
    "master_table = create_master_table(preprocessed_shuttles_data_set, preprocessed_companies_data_set, preprocessed_reviews_data_set)\n",
    "master_table.to_csv(\"./data/space_master.csv\", sep=\",\")\n",
    "\n",
    "\n",
    "#Upload it to blob storage\n",
    "default_ds.upload_files(files=['./data/space_master.csv'], # Upload the diabetes csv files in /data\n",
    "                       target_path='space-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)\n",
    "\n",
    "#Get Master Data Table\n",
    "master_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'space-data/space_master.csv'))\n",
    "\n",
    "# Register the tabular dataset for future usage\n",
    "# registered data set is fetch from blob storage\n",
    "master_data_set = master_data_set.register(workspace=ws, \n",
    "                           name='space master dataset',\n",
    "                           description='master data',\n",
    "                           tags = {'format':'CSV'},\n",
    "                           create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "\t space master dataset version 1\n",
      "\t space shuttles dataset version 1\n",
      "\t space reviews dataset version 1\n",
      "\t space companies dataset version 1\n"
     ]
    }
   ],
   "source": [
    "#Rerturn all versions of given dataset\n",
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, 'version', dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting space_pipeline_dir/train_space.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/train_space.py\n",
    "\"\"\"\n",
    "    #Data Science Step\n",
    "    #Generate a script that create/train a model of simple linear regression\n",
    "    #The Azure ML pipeline will read in this file along with the parser\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Import ML libraries\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Get parameters\n",
    "# This will be read in by pipeline parser when call\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"space_model\", help='output folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the spaceflight data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "space = run.input_datasets['space_master'].to_pandas_dataframe()\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = space[['engines','passenger_capacity','crew','d_check_complete','moon_clearance_complete']].values, space['price'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=3)\n",
    "\n",
    "# Train Linear Regression model\n",
    "print('Training a Linear Regression model')\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# calculate R2 Score\n",
    "y_pred = model.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print('Regressor Model R2 Score:', score)\n",
    "run.log('R2 Score', np.float(score))\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting space_pipeline_dir/register_space.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/register_space.py\n",
    "\"\"\"\n",
    "    #Data Science Step\n",
    "    #Generate a script to register the model\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"space_model\", help='model location')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'space_model',\n",
    "               tags={'Training context':'Pipeline'})\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "#Prepare Compute Enviornment and Cluster\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"aml-cluster\"\n",
    "\n",
    "# Verify that cluster exists\n",
    "try:\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           max_nodes=4,\n",
    "                                                           idle_seconds_before_scaledown=1800)\n",
    "    pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "#show the fetching of the cluser\n",
    "pipeline_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "#Configure Enviornment + Dependencies\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "# An enviornment is a virtual space\n",
    "# containing all dependencies needed to train the model\n",
    "space_env = Environment(\"space-pipeline-env\")\n",
    "space_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "space_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies\n",
    "space_packages = CondaDependencies.create(conda_packages=['scikit-learn','pandas'],\n",
    "                                             pip_packages=['azureml-sdk'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "space_env.python.conda_dependencies = space_packages\n",
    "\n",
    "# Register the environment (just in case you want to use it again)\n",
    "space_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'space-pipeline-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "#Pipeline generation\n",
    "#Actual pipeline construction here\n",
    "\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "# Get the training dataset\n",
    "space_ds = ws.datasets.get(\"space master dataset\")\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "#picking the estimator (recall the script we created earlier with the model)\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                        compute_target = pipeline_cluster,\n",
    "                        environment_definition=pipeline_run_config.environment,\n",
    "                        entry_script='train_space.py')\n",
    "\n",
    "# Step 1, run the estimator to train the model\n",
    "# Store the model in the output folder\n",
    "train_step = EstimatorStep(name = \"Train Model\",\n",
    "                           estimator=estimator, \n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           inputs=[space_ds.as_named_input('space_master')],\n",
    "                           outputs=[model_folder],\n",
    "                           compute_target = pipeline_cluster,\n",
    "                           allow_reuse = True)\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "register_step = PythonScriptStep(name = \"Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"register_space.py\",\n",
    "                                arguments = ['--model_folder', model_folder],\n",
    "                                inputs=[model_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Train Model [3f8aeff0][a1377079-fddf-4184-87f5-2d6b4a623fbf], (This step will run and generate new outputs)\n",
      "Created step Register Model [1b938521][12e58df4-7408-4c64-9bd6-a8735bed9694], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun a4808e11-5a5f-42a7-92f3-0270113061a8\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/space-training-pipeline/runs/a4808e11-5a5f-42a7-92f3-0270113061a8?wsid=/subscriptions/812800e3-0579-4b9a-b1a6-a53215573bf6/resourcegroups/Pipeline-Demo/workspaces/Space-Flight-Predictor\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b875b396204720a7813250ab3253cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: a4808e11-5a5f-42a7-92f3-0270113061a8\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/space-training-pipeline/runs/a4808e11-5a5f-42a7-92f3-0270113061a8?wsid=/subscriptions/812800e3-0579-4b9a-b1a6-a53215573bf6/resourcegroups/Pipeline-Demo/workspaces/Space-Flight-Predictor\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/space-training-pipeline/runs/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9?wsid=/subscriptions/812800e3-0579-4b9a-b1a6-a53215573bf6/resourcegroups/Pipeline-Demo/workspaces/Space-Flight-Predictor\n",
      "StepRun( Train Model ) Status: NotStarted\n",
      "StepRun( Train Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt\n",
      "========================================================================================================================\n",
      "2020-05-31T03:45:45Z Starting output-watcher...\n",
      "2020-05-31T03:45:46Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "0950189ae61475f05582ff8ba476ad250b2fda8b91cfe2acd572facab7ae0019\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt\n",
      "===============================================================================================================\n",
      "Entering job preparation. Current time:2020-05-31T03:45:47.833674\n",
      "Starting job preparation. Current time:2020-05-31T03:45:48.494812\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: c5bb2f37-0f69-4e10-b5d2-2b7da54e9f29\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 50\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/05/31 03:45:52 Starting App Insight Logger for task:  runTaskLet\n",
      "Entering context manager injector. Current time:2020-05-31T03:45:53.833591\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 111\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ train_space.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/space-flight-predictor/azureml/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/mounts/workspaceblobstore/azureml/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/model_folder']\n",
      "After variable expansion, calling script [ train_space.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/space-flight-predictor/azureml/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/mounts/workspaceblobstore/azureml/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/model_folder']\n",
      "\n",
      "Loading Data...\n",
      "/azureml-envs/azureml_7b128fbfa600b67b9d3fa44f93754ed3/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py:722: UserWarning: Your pandas and pyarrow versions are incompatible. Please install pyarrow>=0.12.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install pyarrow>=0.12.0 --upgrade\n",
      "  warnings.warn('Your pandas and pyarrow versions are incompatible. '\n",
      "Training a Linear Regression model\n",
      "Regressor Model R2 Score: 0.43443800375372177\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 111\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 1.5401442050933838 seconds\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-05-31T03:46:32.435757\n",
      "Starting job release. Current time:2020-05-31T03:46:33.983717\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 335\n",
      "Entering context manager injector. Current time:2020-05-31T03:46:34.005678\n",
      "Job release is complete. Current time:2020-05-31T03:46:38.595128\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': '2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-05-31T03:45:44.167357Z', 'endTimeUtc': '2020-05-31T03:46:41.929143Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'c5bb2f37-0f69-4e10-b5d2-2b7da54e9f29', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'a1377079-fddf-4184-87f5-2d6b4a623fbf', 'azureml.pipelinerunid': 'a4808e11-5a5f-42a7-92f3-0270113061a8', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'e014010b-2948-450c-b370-369d2f65a04c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'space_master', 'mechanism': 'Direct'}}], 'runDefinition': {'script': 'train_space.py', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'space_master': {'dataLocation': {'dataset': {'id': 'e014010b-2948-450c-b370-369d2f65a04c'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'space_master', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment space-training-pipeline Environment', 'version': 'Autosave_2020-05-31T03:34:26Z_3961b0ba', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk~=1.6.0']}, 'scikit-learn', 'pandas'], 'name': 'azureml_7b128fbfa600b67b9d3fa44f93754ed3'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/azureml-logs/55_azureml-execution-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt?sv=2019-02-02&sr=b&sig=C%2Bsz83RHvD9RmaUUSnHTqY8Bv06nYurh8yfCCMoylOM%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'azureml-logs/65_job_prep-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/azureml-logs/65_job_prep-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt?sv=2019-02-02&sr=b&sig=EH9htGhMpWqSdLmwficfPiopYWTtFyRJBa33nA6L%2B4I%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=1kl09brCgJ4zb4ncHIfkK2snNb6pM4xGSdgYXx7jn1g%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'azureml-logs/75_job_post-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/azureml-logs/75_job_post-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt?sv=2019-02-02&sr=b&sig=WXMyqAwVMaW4Solv1UdPfeTvnOgWf9oLcH5QrVLGs34%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'azureml-logs/process_info.json': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=%2F7X9s84L5JX6zGyEDsXmHet0xDi0gaE6QHA%2BfsMe9F4%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'azureml-logs/process_status.json': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=yWaOveAjbAQvJytz1jtgrm7dVVEFcoK71zRSVZTzWDw%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'logs/azureml/111_azureml.log': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/logs/azureml/111_azureml.log?sv=2019-02-02&sr=b&sig=B4aiLK0EAdHzQo6HCO49BNgEBie9lQZIL%2B3MXemwtA8%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=3U0Zkvp7KgStW6MkkylPE%2FjL5Td4eaLTdWorLwRm3vo%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=%2BFd3rospQv2T%2BJjaj%2B7dtpWJKFN93zw9WSiOlgnrnNo%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=02rEZm0eJEmWzUMBot9EjcU7XxfPvHbBSVEbhLsjGZU%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=Qf3H6hP9vAXMBGXjbehcwgrxBu4m4eYgR8wm2V7GPNQ%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=64Qwr67UpBe7In%2F6DDJEFUE%2BTmbJCoAxWasIM7neJik%3D&st=2020-05-31T03%3A36%3A51Z&se=2020-05-31T11%3A46%3A51Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 492aec92-1bb6-4276-aae8-69047759629a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/space-training-pipeline/runs/492aec92-1bb6-4276-aae8-69047759629a?wsid=/subscriptions/812800e3-0579-4b9a-b1a6-a53215573bf6/resourcegroups/Pipeline-Demo/workspaces/Space-Flight-Predictor\n",
      "StepRun( Register Model ) Status: NotStarted\n",
      "StepRun( Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt\n",
      "========================================================================================================================\n",
      "2020-05-31T03:47:01Z Starting output-watcher...\n",
      "2020-05-31T03:47:01Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "11c2d28d6cd54204be579b02e2f467d30f60774fc7b6955adcd5cd13ecf8afff\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt\n",
      "===============================================================================================================\n",
      "Entering job preparation. Current time:2020-05-31T03:47:03.336112\n",
      "Starting job preparation. Current time:2020-05-31T03:47:03.973660\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: c5bb2f37-0f69-4e10-b5d2-2b7da54e9f29\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 49\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-05-31T03:47:05.553792\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/05/31 03:47:08 Starting App Insight Logger for task:  runTaskLet\n",
      "Entering context manager injector. Current time:2020-05-31T03:47:09.571801\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 108\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ register_space.py ] with arguments: ['--model_folder', '/mnt/batch/tasks/shared/LS_root/jobs/space-flight-predictor/azureml/492aec92-1bb6-4276-aae8-69047759629a/mounts/workspaceblobstore/azureml/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/model_folder']\n",
      "After variable expansion, calling script [ register_space.py ] with arguments: ['--model_folder', '/mnt/batch/tasks/shared/LS_root/jobs/space-flight-predictor/azureml/492aec92-1bb6-4276-aae8-69047759629a/mounts/workspaceblobstore/azureml/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/model_folder']\n",
      "\n",
      "Loading model from /mnt/batch/tasks/shared/LS_root/jobs/space-flight-predictor/azureml/492aec92-1bb6-4276-aae8-69047759629a/mounts/workspaceblobstore/azureml/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/model_folder\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-05-31T03:47:18.059506\n",
      "Starting job release. Current time:2020-05-31T03:47:19.669482\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 145\n",
      "Entering context manager injector. Current time:2020-05-31T03:47:19.689569\n",
      "Job release is complete. Current time:2020-05-31T03:47:20.967425\n",
      "\n",
      "StepRun(Register Model) Execution Summary\n",
      "==========================================\n",
      "StepRun( Register Model ) Status: Finished\n",
      "{'runId': '492aec92-1bb6-4276-aae8-69047759629a', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-05-31T03:47:04.614285Z', 'endTimeUtc': '2020-05-31T03:47:22.887083Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'c5bb2f37-0f69-4e10-b5d2-2b7da54e9f29', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '12e58df4-7408-4c64-9bd6-a8735bed9694', 'azureml.pipelinerunid': 'a4808e11-5a5f-42a7-92f3-0270113061a8', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'register_space.py', 'useAbsolutePath': False, 'arguments': ['--model_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/2a3c3d1a-6697-4c71-94c9-d2ef5b4b4bf9/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment space-training-pipeline Environment', 'version': 'Autosave_2020-05-31T03:34:26Z_3961b0ba', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk~=1.6.0']}, 'scikit-learn', 'pandas'], 'name': 'azureml_7b128fbfa600b67b9d3fa44f93754ed3'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}, 'cmAksCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/azureml-logs/55_azureml-execution-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt?sv=2019-02-02&sr=b&sig=WgO%2BolydoXYQL4tt2%2BF%2FuxepPLcpV32qJ7prqwyRbsY%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'azureml-logs/65_job_prep-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/azureml-logs/65_job_prep-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt?sv=2019-02-02&sr=b&sig=SFRz2WspAT%2BvmFn%2FQQZN%2BeexMz8rjspWDIGv%2ByJCG%2BE%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=3mVxZiFAcrMk2filzi6f6LSlj6lwxnAQohcRXPbBuiU%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'azureml-logs/75_job_post-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/azureml-logs/75_job_post-tvmps_bdd111a6f04320dd7108cc5d1a9ac23fd1c8d6c1b5ba5369c9b78a760e5b5ddb_d.txt?sv=2019-02-02&sr=b&sig=c%2Fp3EDX7USHumV06KwQVLvB380t13EO%2FWl6Xq4zgSTc%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'azureml-logs/process_info.json': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=UeqyO%2FXt3iNFi2eLawNsHoRYBa9TfLnCPHkn8GvezY8%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'azureml-logs/process_status.json': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=pSskyV%2B8apPU1Y7aK%2F1Zfc4uICKe3tJ3gQ0%2BUOSJNcg%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'logs/azureml/108_azureml.log': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/logs/azureml/108_azureml.log?sv=2019-02-02&sr=b&sig=mkTFvV9UVckkj21YPdLq4RIqjtS7OGBZ1OiVtdzl65s%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=N0pAlcyvblVJiF2A3QazyGCyu3DZ3%2FradQOx1ocznwA%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=wJADV8r%2Bshp0eX%2BYFUYmfokM2m15zslSgiDBx4AtBi8%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=EIAiZw%2Fz6dTi%2F2cwTgxrfvtOBPBJax6BRWOPVbw5aRY%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=Fxc4ApyyeJtAtl1Fm6466RZDBQW%2BvA5xOAQR5%2F11vEs%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.492aec92-1bb6-4276-aae8-69047759629a/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=JCjlP5R5dFQarKV8lMDmvJaR5%2FwW9TdDMr3%2FD4ibA1c%3D&st=2020-05-31T03%3A37%3A29Z&se=2020-05-31T11%3A47%3A29Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'a4808e11-5a5f-42a7-92f3-0270113061a8', 'status': 'Completed', 'startTimeUtc': '2020-05-31T03:42:41.168568Z', 'endTimeUtc': '2020-05-31T03:47:28.066009Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.a4808e11-5a5f-42a7-92f3-0270113061a8/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=nSJUu5k6i4H2IpTk2vNGoSqV%2FDkuRRCE8%2FgLONe9Bxc%3D&st=2020-05-31T03%3A37%3A33Z&se=2020-05-31T11%3A47%3A33Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.a4808e11-5a5f-42a7-92f3-0270113061a8/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=uzZlNEnb2ajLJpknXDSTnHQmu%2BHCmOM9Faoao4DLH1U%3D&st=2020-05-31T03%3A37%3A33Z&se=2020-05-31T11%3A47%3A33Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://spaceflightpre2444328746.blob.core.windows.net/azureml/ExperimentRun/dcid.a4808e11-5a5f-42a7-92f3-0270113061a8/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=crHtn4awRSLlaQFdd09w4CN7PF6WBs89wCoN9bCBMhw%3D&st=2020-05-31T03%3A37%3A33Z&se=2020-05-31T11%3A47%3A33Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the pipeline with the steps defined previously\n",
    "#Run the pipeline after full construction\n",
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [train_step, register_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = 'space-training-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "#Run the pipeline here\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space_model version: 1\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Output\n",
    "# See all models currently trained on this workspace - and its corresponding version \n",
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eastus.api.azureml.ms/pipelines/v1.0/subscriptions/812800e3-0579-4b9a-b1a6-a53215573bf6/resourceGroups/Pipeline-Demo/providers/Microsoft.MachineLearningServices/workspaces/Space-Flight-Predictor/PipelineRuns/PipelineSubmit/624fb15c-4070-423e-ba2e-8851e9db40de\n"
     ]
    }
   ],
   "source": [
    "published_pipeline = pipeline.publish(name=\"Space_Training_Pipeline\",\n",
    "                                      description=\"Trains space model\",\n",
    "                                      version=\"1.0\")\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'35b5b8cf-3983-46c8-9783-ff94ffad73bc'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "experiment_name = 'Space_Training_Pipeline'\n",
    "\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2bbd08c49d407fb1cced1144af6587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
